# DynRec Optimization Log
# Timestamp: 2025-04-08 15:43:32

[Configuration]
Loss Function: AmplitudePhaseL2
Loss Config: {"numeric":{"amp_weight":1.0,"phase_weight":1.0},"type":"AmplitudePhaseL2"}
Regularization: L2
Regularization Config: {"type":"L2"}
Lambda: 0.01
Target: 
(1.2,0.3) 
(2.1,0.4) 
(1.8,-0.2) 
...
Initial x0: 
0 
0 
0 


[Optimization]
Optimization Name: momentum
Optimization Config: {"learning_rate":0.01,"max_iter":100,"tolerance":1e-06}

[Iterations]
Iter	Loss	GradientNorm
0	9.48768690	0.14375932
1	9.40545959	9.51077425
2	8.49497010	9.06311093
3	6.96488633	8.19877486
4	5.12740398	7.02121628
5	3.31079910	5.61929308
6	1.78383138	4.08393257
7	0.71719203	2.50374591
8	0.17031164	0.96296903
9	0.10108732	0.49421543
10	0.39238593	1.75440404
11	0.88728315	2.81045307
12	1.42492890	3.62467611
13	1.87035680	4.18102485
14	2.13393274	4.47802968
15	2.17885081	4.52709863
16	2.01757353	4.35061597
17	1.69996509	3.97973758
18	1.29686331	3.45199028
19	0.88295882	2.80880570
20	0.52224183	2.09311745
21	0.25818772	1.34715326
22	0.10957363	0.61072368
23	0.07161900	0.09263110
24	0.12122758	0.70438947
25	0.22459153	1.22723123
26	0.34531707	1.63823223
27	0.45148706	1.92836543
28	0.52057124	2.09556038
29	0.54169549	2.14396968
30	0.51535570	2.08311761
31	0.45111282	1.92689260
32	0.36407325	1.69243618
33	0.27102882	1.39898828
34	0.18702680	1.06674725
35	0.12291500	0.71580470
36	0.08412473	0.36525709
37	0.07067856	0.03669966
38	0.07818813	0.27109094
39	0.09947127	0.52907564
40	0.12637509	0.73569048
41	0.15143214	0.88583959
42	0.16907867	0.97782057
43	0.17629510	1.01295707
44	0.17266132	0.99521732
45	0.15992758	0.93075284
46	0.14127146	0.82737947
47	0.12043614	0.69403029
48	0.10093002	0.54021065
49	0.08542222	0.37548602
50	0.07540718	0.20905563
51	0.07114845	0.05019638
52	0.07185883	0.09874214
53	0.07603897	0.22533077
54	0.08188232	0.32860330
55	0.08765979	0.40560281
56	0.09201749	0.45516641
57	0.09414971	0.47761066
58	0.09383908	0.47454850
59	0.09138182	0.44867677
60	0.08743347	0.40353514
61	0.08281849	0.34324895
62	0.07834532	0.27226968
63	0.07465971	0.19512577
64	0.07215571	0.11619643
65	0.07094990	0.03953851
66	0.07091124	0.03157755
67	0.07173076	0.09384332
68	0.07301060	0.14535215
69	0.07435261	0.18463206
70	0.07543021	0.21098800
71	0.07603368	0.22442715
72	0.07608561	0.22558622
73	0.07562927	0.21563703
74	0.07479734	0.19617589
75	0.07377014	0.16910340
76	0.07273334	0.13650185
77	0.07184265	0.10051668
78	0.07120081	0.06325082
79	0.07084862	0.02671023
80	0.07076908	0.00831273
81	0.07090125	0.03831912
82	0.07115960	0.06382495
83	0.07145413	0.08369787
84	0.07170747	0.09751289
85	0.07186649	0.10519777
86	0.07190720	0.10698925
87	0.07183345	0.10338854
88	0.07167072	0.09510993
89	0.07145721	0.08302442
90	0.07123426	0.06810161
91	0.07103804	0.05135255
92	0.07089376	0.03377657
93	0.07081303	0.01631528
94	0.07079416	0.00056830
95	0.07082492	0.01506940
96	0.07088668	0.02769890
97	0.07095895	0.03771848
98	0.07102341	0.04489891
99	0.07106684	0.04917378

[Result]
Final Loss: 0.07108247
Iterations: 100
Stop Reason: completed
x_opt: 1.10189405 1.11211853 1.19576782 

[Summary(JSON)]
{
    "final_loss": 0.0710824733048262,
    "iterations": 100,
    "stop_reason": "completed",
    "x_opt": [
        1.10189404824883,
        1.1121185273214718,
        1.195767821686248
    ]
}
