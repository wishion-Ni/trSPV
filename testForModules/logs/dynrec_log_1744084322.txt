# DynRec Optimization Log
# Timestamp: 2025-04-08 11:52:02

[Configuration]
Loss Function: AmplitudePhaseL2
Loss Config: {"numeric":{"amp_weight":1.0,"phase_weight":1.0},"type":"AmplitudePhaseL2"}
Regularization: L2
Regularization Config: {"type":"L2"}
Lambda: 0.01
Target: 
(1.2,0.3) 
(2.1,0.4) 
(1.8,-0.2) 
...
Initial x0: 
0 
0 
0 


[Iterations]
Iter	Loss	GradientNorm
1	9.48768690	0.14375932
2	8.59709890	9.11724652
3	8.01201881	8.79878527
4	7.36788549	8.43443945
5	6.71775026	8.05008344
6	6.08132083	7.65525296
7	5.46830037	7.25475951
8	4.88421515	6.85154252
9	4.33246623	6.44766171
10	3.81520631	6.04471797
11	3.33376493	5.64405679
12	2.88887385	5.24687584
13	2.48079491	4.85428555
14	2.10939693	4.46734430
15	1.77420496	4.08707914
16	1.47443441	3.71449720
17	1.20901733	3.35059127
18	0.97662525	2.99634105
19	0.77569145	2.65271149
20	0.60443445	2.32064905
21	0.46088407	2.00107710
22	0.34291038	1.69489188
23	0.24825617	1.40296224
24	0.17457238	1.12614052
25	0.11945627	0.86530616
26	0.08049122	0.62152051
27	0.05528733	0.39668186
28	0.04152119	0.19795016
29	0.03697383	0.10011871
30	0.03956514	0.22247473
31	0.04738367	0.37266301
32	0.05871085	0.51122184
33	0.07203858	0.63415335
34	0.08608014	0.74074723
35	0.09977405	0.83105323
36	0.11228124	0.90542737
37	0.12297626	0.96440213
38	0.13143304	1.00863457
39	0.13740645	1.03887851
40	0.14081057	1.05596549
41	0.14169491	1.06078949
42	0.14021946	1.05429334
43	0.13662973	1.03745639
44	0.13123260	1.01128292
45	0.12437362	0.97679129
46	0.11641640	0.93500384
47	0.10772459	0.88693741
48	0.09864651	0.83359464
49	0.08950285	0.77595589
50	0.08057719	0.71497189
51	0.07210951	0.65155710
52	0.06429235	0.58658379
53	0.05726940	0.52087681
54	0.05113634	0.45520929
55	0.04594346	0.39029929
56	0.04169984	0.32680777
57	0.03837853	0.26533892
58	0.03592261	0.20644550
59	0.03425161	0.15064896
60	0.03326801	0.09852033
61	0.03286362	0.05117870
62	0.03292543	0.01867456
63	0.03334097	0.04254109
64	0.03400277	0.07721554
65	0.03481210	0.10884522
66	0.03568173	0.13643485
67	0.03653782	0.15981450
68	0.03732097	0.17899840
69	0.03798644	0.19408428
70	0.03850375	0.20522435
71	0.03885569	0.21261247
72	0.03903687	0.21647598
73	0.03905196	0.21706929
74	0.03891377	0.21466824
75	0.03864125	0.20956482
76	0.03825749	0.20206227
77	0.03778790	0.19247038
78	0.03725852	0.18110111
79	0.03669461	0.16826449
80	0.03611948	0.15426493
81	0.03555365	0.13939780
82	0.03501424	0.12394651
83	0.03451466	0.10818011
84	0.03406456	0.09235147
85	0.03366990	0.07669657
86	0.03333331	0.06143566
87	0.03305449	0.04677939
88	0.03283071	0.03295121
89	0.03265736	0.02028822
90	0.03252853	0.00997425
91	0.03243752	0.00878259
92	0.03237733	0.01646377
93	0.03234111	0.02470955
94	0.03232244	0.03210965
95	0.03231564	0.03842276
96	0.03231590	0.04359219
97	0.03231940	0.04761947
98	0.03232332	0.05053531
99	0.03232577	0.05238955
100	0.03232572	0.05324615

[Result]
Final Loss: 0.03232289
Iterations: 100
Stop Reason: completed
x_opt: 1.09921690 1.11666474 1.19477086 

[Summary(JSON)]
{
    "final_loss": 0.03232288524259009,
    "iterations": 100,
    "stop_reason": "completed",
    "x_opt": [
        1.099216900785027,
        1.1166647383269976,
        1.1947708611260606
    ]
}
